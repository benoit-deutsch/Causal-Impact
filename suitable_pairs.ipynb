{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Automated City Pairing for Causal Analysis\n",
                "\n",
                "This notebook iterates through all available cities, identifies suitable control candidates using advanced metrics, and exports the findings to `city_pairings.csv`. This automates the selection process for any configuration of target and controls."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "f2296f1c",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import warnings\n",
                "from statsmodels.tsa.stattools import adfuller, grangercausalitytests\n",
                "from tqdm import tqdm\n",
                "\n",
                "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
                "warnings.simplefilter(action='ignore', category=UserWarning)\n",
                "\n",
                "# Constants from causal_impact.ipynb\n",
                "target_col = 'Barcelona' # Default example\n",
                "pre_beg, pre_end = '2023-01-01', '2023-05-31'\n",
                "t1_thresh = 0.8\n",
                "t2_thresh = 0.6"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8a617330",
            "metadata": {},
            "source": [
                "## 1. Load and Prepare Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "0b5d5e32",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Processing 23 cities...\n"
                    ]
                }
            ],
            "source": [
                "df_long = pd.read_csv('sales_data.csv')\n",
                "df_long['Date'] = pd.to_datetime(df_long['Date'])\n",
                "df = df_long.pivot(index='Date', columns='City', values='Value')\n",
                "df.index.freq = 'D'\n",
                "\n",
                "cities = sorted(df.columns.tolist())\n",
                "print(f\"Processing {len(cities)} cities...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "938d8a02",
            "metadata": {},
            "source": [
                "## 2. Refined Selection Step (Sequential Stationarity)\n",
                "\n",
                "We evaluate each city. A city is selected if it has high correlation AND can be made stationary through our standard pipeline."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "dd5e7a51",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_stationary_transform(series, seasonal_period=7):\n",
                "    \"\"\"Returns (step_name, transform_func) or (None, None).\"\"\"\n",
                "    def is_stationary(s):\n",
                "        try:\n",
                "            return adfuller(s.dropna())[1] < 0.05\n",
                "        except:\n",
                "            return False\n",
                "\n",
                "    if is_stationary(series):\n",
                "        return \"Raw\", lambda s: s\n",
                "    \n",
                "    try:\n",
                "        s_log = np.log(series)\n",
                "        if is_stationary(s_log): return \"Log\", lambda s: np.log(s)\n",
                "        \n",
                "        s_diff = s_log.diff()\n",
                "        if is_stationary(s_diff): return \"Log+Diff\", lambda s: np.log(s).diff()\n",
                "        \n",
                "        s_seasonal = s_diff.diff(seasonal_period)\n",
                "        if is_stationary(s_seasonal): \n",
                "            return \"Log+Diff+Seasonal\", lambda s: np.log(s).diff().diff(seasonal_period)\n",
                "    except:\n",
                "        pass\n",
                "        \n",
                "    return None, None"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d42dbf1f",
            "metadata": {},
            "source": [
                "## 3. Batch Evaluation (Adapting select_best_controls loop)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "f9d4dd7e",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Targets:  61%|██████    | 14/23 [00:02<00:01,  7.04it/s]C:\\Users\\benoi\\AppData\\Roaming\\Python\\Python314\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
                        "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
                        "C:\\Users\\benoi\\AppData\\Roaming\\Python\\Python314\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
                        "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
                        "C:\\Users\\benoi\\AppData\\Roaming\\Python\\Python314\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
                        "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
                        "C:\\Users\\benoi\\AppData\\Roaming\\Python\\Python314\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
                        "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
                        "C:\\Users\\benoi\\AppData\\Roaming\\Python\\Python314\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
                        "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
                        "C:\\Users\\benoi\\AppData\\Roaming\\Python\\Python314\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
                        "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
                        "C:\\Users\\benoi\\AppData\\Roaming\\Python\\Python314\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
                        "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
                        "C:\\Users\\benoi\\AppData\\Roaming\\Python\\Python314\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
                        "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
                        "C:\\Users\\benoi\\AppData\\Roaming\\Python\\Python314\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
                        "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
                        "C:\\Users\\benoi\\AppData\\Roaming\\Python\\Python314\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
                        "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
                        "C:\\Users\\benoi\\AppData\\Roaming\\Python\\Python314\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
                        "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
                        "C:\\Users\\benoi\\AppData\\Roaming\\Python\\Python314\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
                        "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
                        "C:\\Users\\benoi\\AppData\\Roaming\\Python\\Python314\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
                        "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
                        "C:\\Users\\benoi\\AppData\\Roaming\\Python\\Python314\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
                        "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
                        "Targets: 100%|██████████| 23/23 [00:03<00:00,  6.91it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Prepared 506 pairings for further analysis.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "source": [
                "results = []\n",
                "df_pre = df.loc[pre_beg:pre_end]\n",
                "\n",
                "for target in tqdm(cities, desc=\"Targets\"):\n",
                "    for city in cities:\n",
                "        if target == city:\n",
                "            continue\n",
                "            \n",
                "        corr_raw = df_pre[target].corr(df_pre[city])\n",
                "        step_name, transform_func = get_stationary_transform(df_pre[city])\n",
                "        \n",
                "        corr_trans = None\n",
                "        granger_p = None\n",
                "        var_ratio = None\n",
                "        \n",
                "        if step_name:\n",
                "            s_city_trans = transform_func(df_pre[city]).dropna()\n",
                "            s_target_trans = transform_func(df_pre[target]).dropna()\n",
                "            \n",
                "            # Behavioral Correlation\n",
                "            joined = pd.concat([s_city_trans, s_target_trans], axis=1).dropna()\n",
                "            corr_trans = joined.iloc[:, 0].corr(joined.iloc[:, 1])\n",
                "            \n",
                "            # Granger Causality\n",
                "            try:\n",
                "                granger_result = grangercausalitytests(joined[[target, city]], maxlag=2, verbose=False)\n",
                "                granger_p = granger_result[1][0]['params_ftest'][1]\n",
                "            except: granger_p = 1.0\n",
                "            \n",
                "            # Variance Ratio (Volatility Matching)\n",
                "            var_ratio = s_city_trans.std() / s_target_trans.std()\n",
                "        \n",
                "        # Initial Assignment with Variance and Correlation Filter\n",
                "        tier = \"None\"\n",
                "        if corr_trans and corr_trans > t1_thresh:\n",
                "            if 0.5 < var_ratio < 2.0:\n",
                "                tier = \"Tier 1 (Strict)\"\n",
                "            else:\n",
                "                tier = \"Rejected (High Variance)\"\n",
                "        elif corr_trans and corr_trans > t2_thresh and corr_raw > t2_thresh:\n",
                "            tier = \"Tier 2 (Fallback)\"\n",
                "        \n",
                "        results.append({\n",
                "            'Target': target,\n",
                "            'City': city,\n",
                "            'Correlation_Raw': corr_raw,\n",
                "            'Correlation_Transformed': corr_trans,\n",
                "            'Granger_p_value': granger_p,\n",
                "            'Variance_Ratio': var_ratio,\n",
                "            'Selection_Tier': tier\n",
                "        })\n",
                "\n",
                "pairings_df = pd.DataFrame(results)\n",
                "print(f\"\\nPrepared {len(pairings_df)} pairings for further analysis.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c4d5e6f7",
            "metadata": {},
            "source": [
                "## 4. Power and Volume Calculator\n",
                "\n",
                "We estimate the **Minimum Detectable Effect (MDE)** to ensure the experiment is sufficiently powered. These metrics are added to all tiered pairings and exported to CSV."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "d5e6f7g8",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Calculating Power: 100%|██████████| 55/55 [00:00<00:00, 468.65it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Saved augmented data to city_pairings.csv\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<style type=\"text/css\">\n",
                            "</style>\n",
                            "<table id=\"T_60fae\">\n",
                            "  <thead>\n",
                            "    <tr>\n",
                            "      <th class=\"blank level0\" >&nbsp;</th>\n",
                            "      <th id=\"T_60fae_level0_col0\" class=\"col_heading level0 col0\" >Target</th>\n",
                            "      <th id=\"T_60fae_level0_col1\" class=\"col_heading level0 col1\" >City</th>\n",
                            "      <th id=\"T_60fae_level0_col2\" class=\"col_heading level0 col2\" >Volume_14d</th>\n",
                            "      <th id=\"T_60fae_level0_col3\" class=\"col_heading level0 col3\" >Volume_30d</th>\n",
                            "      <th id=\"T_60fae_level0_col4\" class=\"col_heading level0 col4\" >MDE_14d (%)</th>\n",
                            "      <th id=\"T_60fae_level0_col5\" class=\"col_heading level0 col5\" >MDE_30d (%)</th>\n",
                            "      <th id=\"T_60fae_level0_col6\" class=\"col_heading level0 col6\" >Impact_14d_Total</th>\n",
                            "      <th id=\"T_60fae_level0_col7\" class=\"col_heading level0 col7\" >Impact_30d_Total</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th id=\"T_60fae_level0_row0\" class=\"row_heading level0 row0\" >21</th>\n",
                            "      <td id=\"T_60fae_row0_col0\" class=\"data row0 col0\" >City_17</td>\n",
                            "      <td id=\"T_60fae_row0_col1\" class=\"data row0 col1\" >City_18</td>\n",
                            "      <td id=\"T_60fae_row0_col2\" class=\"data row0 col2\" >799</td>\n",
                            "      <td id=\"T_60fae_row0_col3\" class=\"data row0 col3\" >1713</td>\n",
                            "      <td id=\"T_60fae_row0_col4\" class=\"data row0 col4\" >2.02%</td>\n",
                            "      <td id=\"T_60fae_row0_col5\" class=\"data row0 col5\" >1.38%</td>\n",
                            "      <td id=\"T_60fae_row0_col6\" class=\"data row0 col6\" >16</td>\n",
                            "      <td id=\"T_60fae_row0_col7\" class=\"data row0 col7\" >24</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_60fae_level0_row1\" class=\"row_heading level0 row1\" >10</th>\n",
                            "      <td id=\"T_60fae_row1_col0\" class=\"data row1 col0\" >City_12</td>\n",
                            "      <td id=\"T_60fae_row1_col1\" class=\"data row1 col1\" >City_18</td>\n",
                            "      <td id=\"T_60fae_row1_col2\" class=\"data row1 col2\" >801</td>\n",
                            "      <td id=\"T_60fae_row1_col3\" class=\"data row1 col3\" >1716</td>\n",
                            "      <td id=\"T_60fae_row1_col4\" class=\"data row1 col4\" >2.35%</td>\n",
                            "      <td id=\"T_60fae_row1_col5\" class=\"data row1 col5\" >1.60%</td>\n",
                            "      <td id=\"T_60fae_row1_col6\" class=\"data row1 col6\" >19</td>\n",
                            "      <td id=\"T_60fae_row1_col7\" class=\"data row1 col7\" >28</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_60fae_level0_row2\" class=\"row_heading level0 row2\" >45</th>\n",
                            "      <td id=\"T_60fae_row2_col0\" class=\"data row2 col0\" >City_8</td>\n",
                            "      <td id=\"T_60fae_row2_col1\" class=\"data row2 col1\" >City_18</td>\n",
                            "      <td id=\"T_60fae_row2_col2\" class=\"data row2 col2\" >802</td>\n",
                            "      <td id=\"T_60fae_row2_col3\" class=\"data row2 col3\" >1718</td>\n",
                            "      <td id=\"T_60fae_row2_col4\" class=\"data row2 col4\" >2.30%</td>\n",
                            "      <td id=\"T_60fae_row2_col5\" class=\"data row2 col5\" >1.57%</td>\n",
                            "      <td id=\"T_60fae_row2_col6\" class=\"data row2 col6\" >18</td>\n",
                            "      <td id=\"T_60fae_row2_col7\" class=\"data row2 col7\" >27</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_60fae_level0_row3\" class=\"row_heading level0 row3\" >51</th>\n",
                            "      <td id=\"T_60fae_row3_col0\" class=\"data row3 col0\" >City_9</td>\n",
                            "      <td id=\"T_60fae_row3_col1\" class=\"data row3 col1\" >City_18</td>\n",
                            "      <td id=\"T_60fae_row3_col2\" class=\"data row3 col2\" >800</td>\n",
                            "      <td id=\"T_60fae_row3_col3\" class=\"data row3 col3\" >1715</td>\n",
                            "      <td id=\"T_60fae_row3_col4\" class=\"data row3 col4\" >2.28%</td>\n",
                            "      <td id=\"T_60fae_row3_col5\" class=\"data row3 col5\" >1.56%</td>\n",
                            "      <td id=\"T_60fae_row3_col6\" class=\"data row3 col6\" >18</td>\n",
                            "      <td id=\"T_60fae_row3_col7\" class=\"data row3 col7\" >27</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_60fae_level0_row4\" class=\"row_heading level0 row4\" >14</th>\n",
                            "      <td id=\"T_60fae_row4_col0\" class=\"data row4 col0\" >City_14</td>\n",
                            "      <td id=\"T_60fae_row4_col1\" class=\"data row4 col1\" >City_18</td>\n",
                            "      <td id=\"T_60fae_row4_col2\" class=\"data row4 col2\" >799</td>\n",
                            "      <td id=\"T_60fae_row4_col3\" class=\"data row4 col3\" >1711</td>\n",
                            "      <td id=\"T_60fae_row4_col4\" class=\"data row4 col4\" >2.43%</td>\n",
                            "      <td id=\"T_60fae_row4_col5\" class=\"data row4 col5\" >1.66%</td>\n",
                            "      <td id=\"T_60fae_row4_col6\" class=\"data row4 col6\" >19</td>\n",
                            "      <td id=\"T_60fae_row4_col7\" class=\"data row4 col7\" >28</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_60fae_level0_row5\" class=\"row_heading level0 row5\" >38</th>\n",
                            "      <td id=\"T_60fae_row5_col0\" class=\"data row5 col0\" >City_2</td>\n",
                            "      <td id=\"T_60fae_row5_col1\" class=\"data row5 col1\" >City_18</td>\n",
                            "      <td id=\"T_60fae_row5_col2\" class=\"data row5 col2\" >799</td>\n",
                            "      <td id=\"T_60fae_row5_col3\" class=\"data row5 col3\" >1713</td>\n",
                            "      <td id=\"T_60fae_row5_col4\" class=\"data row5 col4\" >2.46%</td>\n",
                            "      <td id=\"T_60fae_row5_col5\" class=\"data row5 col5\" >1.68%</td>\n",
                            "      <td id=\"T_60fae_row5_col6\" class=\"data row5 col6\" >20</td>\n",
                            "      <td id=\"T_60fae_row5_col7\" class=\"data row5 col7\" >29</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_60fae_level0_row6\" class=\"row_heading level0 row6\" >34</th>\n",
                            "      <td id=\"T_60fae_row6_col0\" class=\"data row6 col0\" >City_19</td>\n",
                            "      <td id=\"T_60fae_row6_col1\" class=\"data row6 col1\" >City_18</td>\n",
                            "      <td id=\"T_60fae_row6_col2\" class=\"data row6 col2\" >802</td>\n",
                            "      <td id=\"T_60fae_row6_col3\" class=\"data row6 col3\" >1718</td>\n",
                            "      <td id=\"T_60fae_row6_col4\" class=\"data row6 col4\" >2.46%</td>\n",
                            "      <td id=\"T_60fae_row6_col5\" class=\"data row6 col5\" >1.68%</td>\n",
                            "      <td id=\"T_60fae_row6_col6\" class=\"data row6 col6\" >20</td>\n",
                            "      <td id=\"T_60fae_row6_col7\" class=\"data row6 col7\" >29</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_60fae_level0_row7\" class=\"row_heading level0 row7\" >2</th>\n",
                            "      <td id=\"T_60fae_row7_col0\" class=\"data row7 col0\" >Barcelona</td>\n",
                            "      <td id=\"T_60fae_row7_col1\" class=\"data row7 col1\" >City_18</td>\n",
                            "      <td id=\"T_60fae_row7_col2\" class=\"data row7 col2\" >920</td>\n",
                            "      <td id=\"T_60fae_row7_col3\" class=\"data row7 col3\" >1971</td>\n",
                            "      <td id=\"T_60fae_row7_col4\" class=\"data row7 col4\" >2.66%</td>\n",
                            "      <td id=\"T_60fae_row7_col5\" class=\"data row7 col5\" >1.82%</td>\n",
                            "      <td id=\"T_60fae_row7_col6\" class=\"data row7 col6\" >24</td>\n",
                            "      <td id=\"T_60fae_row7_col7\" class=\"data row7 col7\" >36</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_60fae_level0_row8\" class=\"row_heading level0 row8\" >40</th>\n",
                            "      <td id=\"T_60fae_row8_col0\" class=\"data row8 col0\" >City_20</td>\n",
                            "      <td id=\"T_60fae_row8_col1\" class=\"data row8 col1\" >City_18</td>\n",
                            "      <td id=\"T_60fae_row8_col2\" class=\"data row8 col2\" >641</td>\n",
                            "      <td id=\"T_60fae_row8_col3\" class=\"data row8 col3\" >1373</td>\n",
                            "      <td id=\"T_60fae_row8_col4\" class=\"data row8 col4\" >11.91%</td>\n",
                            "      <td id=\"T_60fae_row8_col5\" class=\"data row8 col5\" >8.14%</td>\n",
                            "      <td id=\"T_60fae_row8_col6\" class=\"data row8 col6\" >76</td>\n",
                            "      <td id=\"T_60fae_row8_col7\" class=\"data row8 col7\" >112</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_60fae_level0_row9\" class=\"row_heading level0 row9\" >54</th>\n",
                            "      <td id=\"T_60fae_row9_col0\" class=\"data row9 col0\" >City_Spurious</td>\n",
                            "      <td id=\"T_60fae_row9_col1\" class=\"data row9 col1\" >City_18</td>\n",
                            "      <td id=\"T_60fae_row9_col2\" class=\"data row9 col2\" >838</td>\n",
                            "      <td id=\"T_60fae_row9_col3\" class=\"data row9 col3\" >1796</td>\n",
                            "      <td id=\"T_60fae_row9_col4\" class=\"data row9 col4\" >9.47%</td>\n",
                            "      <td id=\"T_60fae_row9_col5\" class=\"data row9 col5\" >6.47%</td>\n",
                            "      <td id=\"T_60fae_row9_col6\" class=\"data row9 col6\" >79</td>\n",
                            "      <td id=\"T_60fae_row9_col7\" class=\"data row9 col7\" >116</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "<pandas.io.formats.style.Styler at 0x270bed8ac10>"
                        ]
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "def calculate_mde_refined(target_series, control_series, post_days=14, confidence=0.95, power=0.8):\n",
                "    import statsmodels.api as sm\n",
                "    from scipy.stats import norm\n",
                "    \n",
                "    # 1. Critical values\n",
                "    z_alpha = norm.ppf(1 - (1 - confidence) / 2)\n",
                "    z_beta = norm.ppf(power)\n",
                "    z_combined = z_alpha + z_beta\n",
                "    \n",
                "    # 2. Get high-frequency residual noise (Stationary Noise)\n",
                "    y = target_series.diff().dropna()\n",
                "    x = control_series.diff().dropna()\n",
                "    \n",
                "    x_reg = sm.add_constant(x)\n",
                "    model = sm.OLS(y, x_reg).fit()\n",
                "    sigma_daily = np.sqrt(model.mse_resid)\n",
                "    \n",
                "    # 3. Detection Threshold for the TOTAL sum over post_days\n",
                "    total_incremental_units_required = z_combined * sigma_daily * np.sqrt(post_days)\n",
                "    \n",
                "    # Percentage MDE vs baseline total volume\n",
                "    baseline_total_volume = target_series.mean() * post_days\n",
                "    mde_pct = total_incremental_units_required / baseline_total_volume\n",
                "    \n",
                "    return mde_pct, total_incremental_units_required\n",
                "\n",
                "def augment_with_power(df_pairs, df_all, durations=[14, 30]):\n",
                "    \"\"\"Calculates power metrics for all entries with a valid selection tier.\"\"\"\n",
                "    augmented_rows = []\n",
                "    # We only calculate power for Tier 1 and Tier 2 to save time\n",
                "    valid_pairs = df_pairs[df_pairs['Selection_Tier'].str.contains(\"Tier\")].copy()\n",
                "    \n",
                "    for idx, row in tqdm(valid_pairs.iterrows(), total=len(valid_pairs), desc=\"Calculating Power\"):\n",
                "        target, city = row['Target'], row['City']\n",
                "        s_target = df_all[target].loc[pre_beg:pre_end]\n",
                "        s_city = df_all[city].loc[pre_beg:pre_end]\n",
                "        \n",
                "        res = row.to_dict()\n",
                "        for d in durations:\n",
                "            mde_p, mde_a = calculate_mde_refined(s_target, s_city, post_days=d)\n",
                "            res[f\"Volume_{d}d\"] = s_target.mean() * d\n",
                "            res[f\"MDE_{d}d (%)\"] = mde_p\n",
                "            res[f\"Impact_{d}d_Total\"] = mde_a\n",
                "        augmented_rows.append(res)\n",
                "    \n",
                "    return pd.DataFrame(augmented_rows)\n",
                "\n",
                "# Run Power Analysis\n",
                "augmented_pairings = augment_with_power(pairings_df, df)\n",
                "\n",
                "# Merge back with non-tiered results just for the CSV export completeness (optional, but requested)\n",
                "final_export_df = pd.concat([augmented_pairings, pairings_df[~pairings_df['Selection_Tier'].str.contains(\"Tier\")]], sort=False)\n",
                "final_export_df.to_csv('city_pairings.csv', index=False)\n",
                "print(f\"\\nSaved augmented data to city_pairings.csv\")\n",
                "\n",
                "# Preview the Top Rows for the notebook display\n",
                "display_df = augmented_pairings[augmented_pairings['Selection_Tier'] == 'Tier 1 (Strict)'].sort_values('Correlation_Transformed', ascending=False).head(10)\n",
                "\n",
                "# Formatting for Jupyter Display\n",
                "cols_v = [c for c in display_df.columns if \"Volume\" in c]\n",
                "cols_pct = [c for c in display_df.columns if \"(%)\" in c]\n",
                "cols_abs = [c for c in display_df.columns if \"Total\" in c]\n",
                "display_cols = [\"Target\", \"City\"] + cols_v + cols_pct + cols_abs\n",
                "\n",
                "format_dict = {col: \"{:.2%}\" for col in cols_pct}\n",
                "format_dict.update({col: \"{:.0f}\" for col in cols_abs})\n",
                "format_dict.update({col: \"{:.0f}\" for col in cols_v})\n",
                "\n",
                "display_df[display_cols].style.format(format_dict)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "glossary_cell",
            "metadata": {},
            "source": [
                "### Glossary & Interpretation Guide\n",
                "\n",
                "| Term | Definition |\n",
                "| :--- | :--- |\n",
                "| **Target** | The city where you plan to launch the campaign/intervention. |\n",
                "| **Volume_{d}d** | The total expected sales units in the target city over a {d}-day period. |\n",
                "| **Control** | The city acting as the benchmark. |\n",
                "| **MDE (%)** | **Minimum Detectable Effect**. The smallest percentage lift in total sales required over the period for statistical significance. |\n",
                "| **Impact_{d}d_Total** | **Absolute Detection Threshold**. The total number of *additional* units you need to sell across the **entire {d}-day window** to be sure the result is real. |\n",
                "\n",
                "### Example: Target = Barcelona | Control = City_18\n",
                "\n",
                "| Target | Control | Volume_14d | MDE_14d (%) | Impact_14d_Total | Volume_30d | MDE_30d (%) | Impact_30d_Total |\n",
                "| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |\n",
                "| **Barcelona** | **City_18** | **35,000** | **12.85%** | **4,500** | **75,000** | **8.80%** | **6,600** |\n",
                "\n",
                "**How to read this:**\n",
                "\n",
                "1. **The 14-Day Scenario (2 Weeks)**\n",
                "- **Volume_14d (35,000)**: Over 14 days, Barcelona normally sells 35,000 units total.\n",
                "- **Impact_14d_Total (4,500)**: To be statistically significant, your campaign must generate **4,500 extra units** on top of the 35k.\n",
                "- **MDE_14d (12.85%)**: This means you need a **+12.85% lift** in total sales to \"break through\" the daily market noise.\n",
                "\n",
                "2. **The 30-Day Scenario (1 Month)**\n",
                "- **Volume_30d (75,000)**: Over 30 days, sales grow to 75,000 units.\n",
                "- **Impact_30d_Total (6,600)**: Running the test longer improves sensitivity. You only need **6,600 extra units** (not 9,000!) to reach significance.\n",
                "- **MDE_30d (8.80%)**: Your required lift dropped from ~13% to **under 9%**. The test is much more powerful if you wait longer."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
